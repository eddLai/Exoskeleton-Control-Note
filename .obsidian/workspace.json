{
  "main": {
    "id": "78f18c827fa26258",
    "type": "split",
    "children": [
      {
        "id": "e48967b63f22519a",
        "type": "tabs",
        "children": [
          {
            "id": "98340c86c9017c5e",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Reward and Ouput Algorithm Design.md",
                "mode": "source",
                "source": false
              }
            }
          }
        ]
      },
      {
        "id": "14e5669fd925ec56",
        "type": "tabs",
        "children": [
          {
            "id": "4c307bc9028ff55c",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Presentation slide.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "7a07dd1873745d95",
            "type": "leaf",
            "state": {
              "type": "pdf",
              "state": {
                "file": "文獻/s41586-024-07382-4 (1).pdf"
              }
            }
          }
        ],
        "currentTab": 1
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "a10b91e1981c24ca",
    "type": "split",
    "children": [
      {
        "id": "d1950ed6eb740880",
        "type": "tabs",
        "children": [
          {
            "id": "ce267d8792708e43",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "73d33862d7e1ec27",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "12add584f408357f",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "right": {
    "id": "4718cc23948e3b59",
    "type": "split",
    "children": [
      {
        "id": "a30e1e47857e6d1e",
        "type": "tabs",
        "children": [
          {
            "id": "96e3cb2374baef89",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Reward and Ouput Algorithm Design.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "398339d00a4f2181",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Reward and Ouput Algorithm Design.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "752aa0121b12419b",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              }
            }
          },
          {
            "id": "90bb42b3b0ed7c3c",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Reward and Ouput Algorithm Design.md"
              }
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "obsidian-advanced-slides:Show Slide Preview": false
    }
  },
<<<<<<< HEAD
  "active": "7a07dd1873745d95",
  "lastOpenFiles": [
    "Presentation slide.md",
    "文獻/ML app/Papers/Human–exoskeleton interaction portrait.pdf",
=======
  "active": "98340c86c9017c5e",
  "lastOpenFiles": [
    "Presentation slide.md",
>>>>>>> 93da117 (vault backup: 2024-08-26 11:36:39)
    "文獻/s41586-024-07382-4 (1) - 複製.pdf",
    "文獻/s41586-024-07382-4 (1).pdf",
    "Overview of 旺宏競賽：外骨骼力增強系統.md",
    "Cygnus src解析.md",
    "Pasted image 20240512100407.png",
    "Reward and Ouput Algorithm Design.md",
    "計劃/第二階段.md",
    "文獻/conference/ICMST 2024 Abstract_Exoskeleton_賴宏達,沈恩佑,劉芸婷v3.pdf",
    "計劃/開發時間軸規畫.md",
    "文獻/conference/ICMST 2024 Abstract_Exoskeleton_賴宏達,沈恩佑,劉芸婷v2.pdf",
    "test.md",
    "文獻/ML app/Papers/AutoEncoder-based_Safe_Reinforcement_Learning_for_Power_Augmentation_in_a_Lower-limb_Exoskeleton.pdf",
    "文獻/ML app/Papers/Lower Limb Exoskeleton LSTM.pdf",
    "賴宏達SS_final_report/計劃書exoskeleton組v1.1.pdf",
    "賴宏達SS_final_report/SS_期末專題slide.pdf",
    "文獻/conference/~WRL0381.tmp",
<<<<<<< HEAD
=======
    "文獻/conference/~WRD4059.tmp",
>>>>>>> 93da117 (vault backup: 2024-08-26 11:36:39)
    "計劃/第一階段實際開會紀錄.md",
    "Pasted image 20240723160705.png",
    "文獻/ML app/Pasted image 20240107180700.png",
    "Slide pics/Pasted image 20240522175455.png",
    "Slide pics/Pasted image 20240522182005.png",
    "Slide pics/Pasted image 20240522182438.png",
    "Slide pics/Pasted image 20240525151103.png",
    "Slide pics/Pasted image 20240525150434.png",
    "Slide pics/Pasted image 20240524133018.png",
    "Slide pics/Pasted image 20240522182850.png",
    "文獻/KneeBO Contol/Command Table.md",
    "文獻/KneeBO Contol/KneeBO_CMD.md",
    "文獻/KneeBO Contol/KneeBO command list.md",
    "trouble shooting.md",
    "WSL GUI.md",
    "推薦系統.md",
    "GET API.md",
    "文獻/EMG/EMG彙整.md",
    "文件清單.md",
    "文獻/Papers List.md",
    "文獻/RL network/unpack_batch_ddpg code.md",
    "文獻/ML app/python tips.md",
    "文獻/AR/AR開發.md",
    "文獻/RL network/log_softmax與softmax的差異.md",
    "文獻/RL network/distr_projection的詳細內容.md",
    "文獻/RL network/建置python環境.md",
    "文獻/計劃書/計劃書修改紀錄.md",
    "文獻/Plan Graphs/控制規劃.canvas",
    "文獻/ML app/RL overview of training.canvas",
    "文獻/Plan Graphs/Hip實驗.canvas",
    "文獻/Plan Graphs/作動偵測實驗.canvas",
    "文獻/Plan Graphs/當前任務.canvas",
    "Plan Graphs/Hip實驗.canvas",
    "Plan Graphs/控制規劃.canvas",
    "Plan Graphs/作動偵測實驗.canvas",
    "Plan Graphs/當前任務.canvas",
    "ML app/RL overview of training.canvas"
  ]
}