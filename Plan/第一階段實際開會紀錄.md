>[!NOTE] 1/6 ~ 1/16
EMG：
 >- 測試山下實驗室的環狀EMG感測器
 >- 編寫透過EMG對肌力進行測定的程式
 >- 解決感測擾動的問題
 >- 並決定硬體
AR：
>- 完成商品的選擇(確保具外部攝影功能，用於後期電腦視覺的開發) 並與老師討論
>- 完成採購
>- 決定研究AR眼鏡的開發環境
Robotics：
>- 文獻探討(至少3篇)，從力學模型的角度設計一套控制方案，(數學過程)
RL：
>- 文獻探討(至少3篇)，從強化學習的角度設計一套控制方案，[[RL實作-python code]](數學過程)

>[!NOTE] 完成進度：
> - [x] 已經與老師討論過AR眼鏡，並確認了廠商
> - [x] 已經確認開發板的品項
> - [x] 編寫計劃書
> - [x] 經老師審核，並修改格式
> - [x] 完成報名
>
>EMG：熟悉EMG以及寫一點小程式
>AR：找好書本
>Robotics：找了幾篇文獻來看而已
>RL：確定使用PDPG，以及優化Tips，有機會使用Critic處理EMG，Actor要怎麼引入決定使用什麼action，看起來3層NN就可能足夠，採用簡單架構，之後再考慮改用LTSM看會怎麼樣，先開始實作
>
>### 討論：要怎麼做力量增強?
>其實不一定要清楚ML的目標是什麼而是給他一個適合特定方向學習的架構，然後讓他去理解並得到操作的奇妙方法
>運動意圖然後進行電機的強化，或者完整的人體建模
>>要做力量增強：決定Actor的Actions，以及判斷使用Actions的方法，最好是DNN比較好嵌入
>>- DMPs能夠模仿動作：調整角度即可達到順向控制，並還原最佳狀態，但整個流程的自動化需要再調整參數
>>- DMPs用來優化將需要的軌跡轉關節，用於進行順向控制
>>- Adaptive oscillator把步態視為Wave能夠預測意圖，簡單的3層NN，或者軌跡：整體自動化，輸出力量、角度等多重資訊
>>- LTSM做動作預測，引入多個關節資料

 討論是為了讓大家了解自己要做什麼，大家對開發還不夠熟

>[!NOTE] 1/17 ~ 1/24
EMG：每兩天找一篇關於EMG的ML處理框架的文獻，我要整合到Critic模型裏頭
AR：
>- [x] 找一本書來看，講詳細的開發流程，以Android手機端進行開發好方便移植
>- [x] 找老師跟廠商確認我們的開發流程對不對，硬體能不能支援
>目標：
>- 做虛擬教練的動畫
>- 手勢骨架去操作使用者介面
>
>Robotics：每兩天找一篇論文來討論，保持對數學的最低限度理解就夠，重點是要寫得出程式，我研究其中ML的部分，你研究其他部分的數學，我們滾動式修正控制策略
>RL：開始寫程式的框架
>### 發現問題
>- 怎麼給力矩
>- Continuous Action怎麼設定

1/21 規劃一套方案，並且要2,3張投影片，介紹怎麼跟Exo作互動。
~ 4/8

>[!NOTE] 1/24 ~ 1/31
EMG：實作程式，並先用LAB的設備看狀況如何
AR：盡全力開發，1/31給我之後開發時間規劃
>- 做虛擬教練的動畫
>- 手勢骨架去操作使用者介面
>
>Robotics：每兩天找一篇論文來討論，保持對數學的最低限度理解就夠，重點是要寫得出程式，我研究其中ML的部分，你研究其他部分的數學，我們滾動式修正控制策略
>- 鎖角度在+/- 70度
>- 確認PID
>RL：開始寫程式的框架，完全可以直接拿來用，而不需要進行太多調整，再來就是做串接就好

>[!NOTE] (1/24~1/31)
>EMG：從EMG偵測股四頭肌的肌力大小(以python寫)，先熟悉程式碼
>- [x] 做濾波
>- [x] 肌力判斷
>
>AR：
>- [x] 手勢辨識：Unity開VR SDK去調用手勢辨識的(手勢SDK)
>- [x] 虛擬教練動畫：導入模型
>
>Robotics：
>- [x] 熟悉RL
>
>RL：
>- [ ] Cont. actions的DQN架構

>[!NOTE] (1/31~2/7)
>EMG：從EMG偵測股四頭肌的肌力大小(以python寫)
>卡在設備串流
>- [x] 先測試RAW DATA，2/15晚上
>- [ ] 實際串接，測擾動，確認分成十級2/19
>
>AR：
>- [ ] 使用者介面：單一按鍵就好，怎麼呈現都可以(追蹤位置SDK)，用Unity在windows中使用內置攝影機進行demo 2/19
>- [ ] 改成抓平面的SDK 2/19
>
>Robotics：
>- [x] 理解DQN(寫程式)
>- [x] 定義週期
>- [ ] DQN的Reward function要怎麼寫 把EMG轉成回饋(用PTAN寫程式)(要設計成+/-) 2/19
>
>RL：
>- [x] 實現3層DNN架構
>
>關於Reward的討論
>要抓步態週期，因為不可能做單點的EMG肌電判讀
>初始狀態開始，越走越輕鬆，前幾次擺動抓出pattern，單純蒐集資料
>動態抓pattern，跟Baseline做比較希望整體使用的量級下移
>Reward = 0，2/19
>2/19實際行走測試程式
>Actions、

>[!NOTE] (2/14~2/24)
>EMG：寫從Reward  Function的串接程式
>
>AR：
>- [ ] 運動防護：外骨骼資訊透過WiFi AP導入 (WiFi通訊SDK) (找賴宏達)
>- [ ] 運動防護：先完成以下的語音示警(語音SDK)(OpenXR SDK位置)
>- [x] 虛擬教練動畫-運動姿勢：
>	- 直接導入動作動畫
>	- 在Unity中製作動畫
>
>Robotics：
>- [ ] 寫從Reward  Function的串接程式
>- [ ] 寫NN的驗證方法
>
>- [ ] 不用先寫一個步態週期的偵測，因為能做到預測就不用，先看EMG訊號週期再來討論
>
>RL：
>完成映射多少力矩；action = np.clip(action, -1, 1)已經限制正負弧度
>obs = Env.reset()，Env.step()雖然陌生但是是必要的，也已經寫好沒有很難
>現實中訓練的提示，我在環境reset的時候要進行通知，然後讓他繼續，手動停止機制
>- [x] 實際Training的操作介面，先串伺服器，所以要把cuda加速的東西寫在
>- [x] ESP32與Action的串接，硬體組裝
>- [x] 鎖角度在+/- 70度
>- [x] 測試內部PID
>- [x] 整合開始做模型的Trainning
>
>- [x] 試試看給力矩，角度會有中間時間的問題
>- [ ] 建虛擬完整模型，從正到負的步態初期，
>- [ ] 肌肉貼哪裡
>
>我自己想沒有用，要帶大家看過整個流程知道問題在哪裡

>[!NOTE] (2/21~2/24)
>賴宏達：
>- [ ] AR WiFi通訊SDK
>- 即時訓練資訊顯示的介面(原本main.py的內容)SummaryWriter就看得到了，顯示reward
>	- [x] Loss function
>	- [x] Reward
>	- [x] 所有角度
>	- [x] 想一下評估方法
>- [x] 輸出改加速度(力矩)，待測試
>
>Tommy
>- [x] OpenXR 語音SDK，串聲音可以，自動化聲音(大概看計劃書可以寫)
>- [ ] Webcam Unity Demo -> OpenXR 地面偵測
>
>沈恩佑&Polly
>- [x] 寫從Reward  Function(我只要EMG的就好)
>- [x] 研究EMG訊號週期，確認擾動狀況
>- [ ] 決定貼片位置

>[!NOTE] (2/24~2/28)
>- [ ] 程式封裝：把Unity寫好的內容包成App，顯示在VR眼鏡中
>- [x] 硬體組裝：導入EMG資料 (USB通訊SDK) (找Polly)
>- [x] 設定AMD板子(不用)
>- [x] 測試AMD板子能不能做training(不用)

>[!NOTE] ## (2/28~3/11)
>賴宏達
>- [x] 統一做時間離散化0.033, 0.05, 完成動作時間func
>- [ ] 處理client_order中的UART發送實現方法
>>期待在不使用错误处理机制的情况下通过WiFi无损还原UART数据，在实际应用中可能不太现实。由于无线网络本身的不稳定性（如信号衰减、干扰和数据包丢失等问题），几乎总是需要一定形式的错误处理来确保数据传输的可靠性。理想情况下，可以通过设计健壮的通信协议和使用高效的数据传输机制（例如，数据校验和重传策略）来最小化错误发生的概率，但完全避免使用错误处理机制可能会导致数据完整性无法得到保证。
>
>- [ ] 確認env在D4PG中的使用
>- [ ] Quest3 Wifi API
>
>沈恩佑
>- [x] 修改成實時濾坡，串Reward function
>- [x] 整合EMG內容進入env
>
>Tommy
>2/28
>- [ ] Webcam Unity Demo -> OpenXR 地面偵測
>- [ ] 手勢偵測卡在VR眼鏡還沒來
>
>3/6
>- [ ] Quest Unity Demo
>- [ ] OpenXR 地面偵測
>- [ ] 手勢偵測卡在VR眼鏡還沒來
>
>Polly
>3/6未達，3/8補
>- [x] EMG貼片位置，數量，對於大腿代表性的
>- [x] 運動防護的判斷邏輯決策樹，輸入：IMU三軸輸入、外骨骼6資訊、EMG運動防護指標
>- [x] 整理文獻
>- [ ] 計劃書大綱
>
>3/6 狀況
>- [x] 問廠商(昨天)
>- [ ] D4PG：如何對時間做離散化
>
>HOLD ON
>- [ ] 研究plotfunc.py，show函數會卡(先想辦法讓兩個圖可以同步，並且用每次更新的數據點來模擬)(暫時沒那麼緊急)
>
>等外骨骼回來測試(3/9)
>- [x] limit限制函數
>- [x] 趕快本週開始做training(盡快)

具體目標：
分成以下階段。並考慮可能遇到的開發面向的風險。
1.	完成AR眼鏡的使用者介面。針對同一個案，建立能夠減少常見動作：上下樓梯、平路行走的肌力使用之機器模型訓練。
2.	導入個性化適應，以遠端連線伺服器進行模型的微調 (fine-tuning) 訓練；並引入欠驅動系統 (underactuated system) 的概念，以及生理步態模型以優化單一行走的穩定度。
3.	AR眼鏡導入電腦視覺技術，提供環境示警作用，諸如：坑洞、懸崖、石塊等。
4.	加入較為快速的動作的選擇，諸如：慢跑、跳躍等功能，優化外骨骼結構、重量，使用腳踝的被動自由度 (passive-installed DOF) 控制機構。
